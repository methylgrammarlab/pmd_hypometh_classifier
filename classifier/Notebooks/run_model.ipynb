{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "run_model",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wz-ud5Hav1O",
        "colab_type": "code",
        "outputId": "216419e9-6187-4123-e5b5-c87f2351385b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "%cd /gdrive "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive\n",
            "/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjO8Tu5MbI-0",
        "colab_type": "code",
        "outputId": "36ca42ec-5b90-411c-dfe3-6e16a892b3b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd /gdrive/My\\ Drive/nn "
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/gdrive/My Drive/nn\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5BI8sNFMb0Lp",
        "colab_type": "code",
        "outputId": "4ba95f4a-418e-47c7-ea47-fe620937884c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import argparse\n",
        "import os\n",
        "import pickle\n",
        "import sys\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "np.random.seed(7)  # for reproducibility\n",
        "\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "\n",
        "# tf.python.control_flow_ops = tf\n",
        "\n",
        "\n",
        "from tensorflow.python.keras.models import Model, load_model\n",
        "from tensorflow.python.keras.layers import Input\n",
        "from tensorflow.python.keras.layers import Dense, Flatten, Dropout\n",
        "from tensorflow.python.keras.layers.convolutional import Conv1D\n",
        "from tensorflow.python.keras.layers.pooling import MaxPooling1D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.python.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "import tensorflow.python.keras.backend as K\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "import matplotlib as mpl\n",
        "\n",
        "mpl.use('Agg')\n",
        "import utils\n",
        "sys.path.append(\".\")\n",
        "from utils import precision, recall, load_data_merged\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lHcO6wobeAjx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_seq_model(input_len):\n",
        "    \"\"\"\n",
        "    Create a sequence model\n",
        "    :param input_len: path to file (consist of train, valid and test data)\n",
        "    \"\"\"\n",
        "    K.clear_session()\n",
        "    # tf.random.set_seed(5005)\n",
        "\n",
        "    # input_node = Input(shape=(input_len, 4), name=\"input\")\n",
        "    # conv1 = Conv1D(filters=90, kernel_size=20, padding='valid', activation=\"relu\", name=\"conv1\")(input_node)\n",
        "    # pool1 = MaxPooling1D(pool_size=10, strides=4, name=\"left_pool1\")(conv1)\n",
        "    # drop1 = Dropout(0.25, name=\"left_drop1\")(pool1)\n",
        "\n",
        "    # conv_merged = Conv1D(filters=100, kernel_size=5, padding='valid', activation=\"relu\", name=\"conv_merged\")(\n",
        "    #         drop1)\n",
        "    # merged_pool1 = MaxPooling1D(pool_size=4, strides=5)(conv_merged)\n",
        "    # merged_drop1 = Dropout(0.25)(merged_pool1)\n",
        "\n",
        "    # conv_merged1 = Conv1D(filters=100, kernel_size=2, padding='valid', activation=\"relu\", name=\"conv_merged2\")(\n",
        "    #     merged_drop1)\n",
        "    # merged_pool2 = MaxPooling1D(pool_size=4, strides=2)(conv_merged1)\n",
        "    # merged_drop2 = Dropout(0.25)(merged_pool2)\n",
        "\n",
        "    # if input_len > 1000:\n",
        "    #     conv_merged = Conv1D(filters=100, kernel_size=5, padding='valid', activation=\"relu\", name=\"conv_merged\")(\n",
        "    #         drop1)\n",
        "    #     merged_pool = MaxPooling1D(pool_size=10, strides=5)(conv_merged)\n",
        "    #     merged_drop = Dropout(0.25)(merged_pool)\n",
        "    #     merged_flat = Flatten()(merged_drop)\n",
        "    # else:\n",
        "    #     merged_flat = Flatten()(merged_drop2)\n",
        "\n",
        "    input_node = Input(shape=(input_len, 4), name=\"input\")\n",
        "    conv1 = Conv1D(filters=90, kernel_size=7, padding='valid', activation=\"relu\", name=\"conv1\")(input_node)\n",
        "    pool1 = MaxPooling1D(pool_size=4, strides=2, name=\"left_pool1\")(conv1)\n",
        "    drop1 = Dropout(0.25, name=\"left_drop1\")(pool1)\n",
        "  \n",
        "    if input_len > 10:\n",
        "        conv_merged = Conv1D(filters=100, kernel_size=5, padding='valid', activation=\"relu\", name=\"conv_merged\")(\n",
        "            drop1)\n",
        "        merged_pool = MaxPooling1D(pool_size=10, strides=5)(conv_merged)\n",
        "        merged_drop = Dropout(0.25)(merged_pool)\n",
        "        merged_flat = Flatten()(merged_drop)\n",
        "    else:\n",
        "        merged_flat =  Flatten()(drop1) \n",
        "\n",
        "    hidden1 = Dense(250, activation='relu', name=\"hidden1\")(merged_flat)\n",
        "    output = Dense(1, activation='sigmoid', name=\"output\")(hidden1)\n",
        "    model = Model(inputs=[input_node], outputs=output)\n",
        "    print(model.summary())\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "def train_diff_model(data_path, res_path, model_name, input_len,\n",
        "                     num_epoch, batchsize, model_path=\"./weights.hdf5\", number_of_folds=1):\n",
        "    \"\"\"\n",
        "    Training the model\n",
        "    :param data_path: path to file (consist of train, valid and test data)\n",
        "    :param res_path:\n",
        "    :param model_name:\n",
        "    :param input_len:\n",
        "    :param num_epoch:\n",
        "    :param batchsize:\n",
        "    :param model_path:\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    print('creating model')\n",
        "    model = create_seq_model(input_len)\n",
        "    print('compiling model')\n",
        "    adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=1e-6)\n",
        "    model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
        "    checkpointer = ModelCheckpoint(filepath=model_path, verbose=1, save_best_only=True)\n",
        "    earlystopper = EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
        "\n",
        "    print('loading data')\n",
        "    x_train_list, y_train_list, x_valid_list, y_valid_list, x_test_seq, y_test = load_data_merged(data_path, input_len, kfold=number_of_folds)\n",
        "\n",
        "    print('fitting the model')\n",
        "    for i in range(len(x_train_list)):\n",
        "      print(\"Using fold %s/%s\" %(i, number_of_folds))\n",
        "      x_train_seq = x_train_list[i]\n",
        "      y_train = y_train_list[i]\n",
        "      x_valid_seq = x_valid_list[i]\n",
        "      y_valid = y_valid_list[i]\n",
        "\n",
        "      history = model.fit(x_train_seq, y_train, epochs=num_epoch, batch_size=batchsize,\n",
        "                          validation_data=(x_valid_seq, y_valid), verbose=2,\n",
        "                          callbacks=[checkpointer, earlystopper, ])  # tb])\n",
        "\n",
        "    print('saving the model')\n",
        "    model.save(os.path.join(res_path, model_name + \".h5\"))\n",
        "\n",
        "    print('testing the model')\n",
        "    score = model.evaluate(x_test_seq, y_test)\n",
        "\n",
        "    for i in range(len(model.metrics_names)):\n",
        "        print(str(model.metrics_names[i]) + \": \" + str(score[i]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xwMTa_vbH8-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ed33e531-a8db-43fd-f553-3242d29116de"
      },
      "source": [
        "train_diff_model(data_path=r\"dataset/classifier_data_ccpg1.pkl\", \n",
        "                 res_path=\"./models\", model_name=\"150cpg\", model_path=\"temp_model\",\n",
        "                 input_len=150, num_epoch=20, batchsize=64, number_of_folds=2)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "creating model\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input (InputLayer)           [(None, 150, 4)]          0         \n",
            "_________________________________________________________________\n",
            "conv1 (Conv1D)               (None, 144, 90)           2610      \n",
            "_________________________________________________________________\n",
            "left_pool1 (MaxPooling1D)    (None, 71, 90)            0         \n",
            "_________________________________________________________________\n",
            "left_drop1 (Dropout)         (None, 71, 90)            0         \n",
            "_________________________________________________________________\n",
            "conv_merged (Conv1D)         (None, 67, 100)           45100     \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 12, 100)           0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 12, 100)           0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 1200)              0         \n",
            "_________________________________________________________________\n",
            "hidden1 (Dense)              (None, 250)               300250    \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 1)                 251       \n",
            "=================================================================\n",
            "Total params: 348,211\n",
            "Trainable params: 348,211\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "compiling model\n",
            "loading data\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fitting the model\n",
            "Using fold 0/2\n",
            "Train on 520739 samples, validate on 520739 samples\n",
            "Epoch 1/20\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.58979, saving model to temp_model\n",
            "520739/520739 - 53s - loss: 0.6046 - acc: 0.6755 - val_loss: 0.5898 - val_acc: 0.6916\n",
            "Epoch 2/20\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.58979 to 0.58768, saving model to temp_model\n",
            "520739/520739 - 52s - loss: 0.5917 - acc: 0.6884 - val_loss: 0.5877 - val_acc: 0.6945\n",
            "Epoch 3/20\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.58768 to 0.58299, saving model to temp_model\n",
            "520739/520739 - 52s - loss: 0.5882 - acc: 0.6912 - val_loss: 0.5830 - val_acc: 0.6953\n",
            "Epoch 4/20\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.58299 to 0.57987, saving model to temp_model\n",
            "520739/520739 - 53s - loss: 0.5859 - acc: 0.6931 - val_loss: 0.5799 - val_acc: 0.6974\n",
            "Epoch 5/20\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 0.57987\n",
            "520739/520739 - 52s - loss: 0.5839 - acc: 0.6947 - val_loss: 0.5814 - val_acc: 0.6984\n",
            "Epoch 6/20\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.57987\n",
            "520739/520739 - 52s - loss: 0.5822 - acc: 0.6959 - val_loss: 0.5811 - val_acc: 0.6995\n",
            "Epoch 7/20\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.57987\n",
            "520739/520739 - 51s - loss: 0.5811 - acc: 0.6966 - val_loss: 0.5804 - val_acc: 0.6998\n",
            "Epoch 8/20\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.57987 to 0.57777, saving model to temp_model\n",
            "520739/520739 - 52s - loss: 0.5798 - acc: 0.6976 - val_loss: 0.5778 - val_acc: 0.6999\n",
            "Epoch 9/20\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.57777\n",
            "520739/520739 - 52s - loss: 0.5783 - acc: 0.6988 - val_loss: 0.5797 - val_acc: 0.6982\n",
            "Epoch 10/20\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.57777\n",
            "520739/520739 - 52s - loss: 0.5778 - acc: 0.6993 - val_loss: 0.5782 - val_acc: 0.7001\n",
            "Epoch 11/20\n",
            "\n",
            "Epoch 00011: val_loss improved from 0.57777 to 0.57760, saving model to temp_model\n",
            "520739/520739 - 52s - loss: 0.5769 - acc: 0.6992 - val_loss: 0.5776 - val_acc: 0.7000\n",
            "Epoch 12/20\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.57760\n",
            "520739/520739 - 52s - loss: 0.5760 - acc: 0.6998 - val_loss: 0.5778 - val_acc: 0.7005\n",
            "Epoch 13/20\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 0.57760\n",
            "520739/520739 - 52s - loss: 0.5748 - acc: 0.7017 - val_loss: 0.5786 - val_acc: 0.7013\n",
            "Epoch 14/20\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 0.57760\n",
            "520739/520739 - 51s - loss: 0.5744 - acc: 0.7017 - val_loss: 0.5793 - val_acc: 0.6992\n",
            "Epoch 15/20\n",
            "\n",
            "Epoch 00015: val_loss improved from 0.57760 to 0.57622, saving model to temp_model\n",
            "520739/520739 - 52s - loss: 0.5738 - acc: 0.7025 - val_loss: 0.5762 - val_acc: 0.7014\n",
            "Epoch 16/20\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.57622\n",
            "520739/520739 - 52s - loss: 0.5734 - acc: 0.7022 - val_loss: 0.5802 - val_acc: 0.7006\n",
            "Epoch 17/20\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 0.57622\n",
            "520739/520739 - 52s - loss: 0.5726 - acc: 0.7032 - val_loss: 0.5774 - val_acc: 0.7021\n",
            "Epoch 18/20\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.57622\n",
            "520739/520739 - 52s - loss: 0.5726 - acc: 0.7029 - val_loss: 0.5766 - val_acc: 0.7014\n",
            "Epoch 19/20\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 0.57622\n",
            "520739/520739 - 52s - loss: 0.5711 - acc: 0.7042 - val_loss: 0.5763 - val_acc: 0.7018\n",
            "Epoch 20/20\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.57622\n",
            "520739/520739 - 52s - loss: 0.5711 - acc: 0.7039 - val_loss: 0.5787 - val_acc: 0.7012\n",
            "Epoch 00020: early stopping\n",
            "Using fold 1/2\n",
            "Train on 520739 samples, validate on 520739 samples\n",
            "Epoch 1/20\n",
            "\n",
            "Epoch 00001: val_loss improved from 0.57622 to 0.56722, saving model to temp_model\n",
            "520739/520739 - 52s - loss: 0.5824 - acc: 0.6957 - val_loss: 0.5672 - val_acc: 0.7081\n",
            "Epoch 2/20\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.56722\n",
            "520739/520739 - 52s - loss: 0.5794 - acc: 0.6982 - val_loss: 0.5681 - val_acc: 0.7081\n",
            "Epoch 3/20\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.56722\n",
            "520739/520739 - 52s - loss: 0.5777 - acc: 0.6996 - val_loss: 0.5677 - val_acc: 0.7082\n",
            "Epoch 4/20\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 0.56722\n",
            "520739/520739 - 52s - loss: 0.5767 - acc: 0.6996 - val_loss: 0.5704 - val_acc: 0.7079\n",
            "Epoch 5/20\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 0.56722\n",
            "520739/520739 - 52s - loss: 0.5754 - acc: 0.7011 - val_loss: 0.5700 - val_acc: 0.7072\n",
            "Epoch 6/20\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.56722\n",
            "520739/520739 - 51s - loss: 0.5745 - acc: 0.7016 - val_loss: 0.5694 - val_acc: 0.7075\n",
            "Epoch 00006: early stopping\n",
            "saving the model\n",
            "testing the model\n",
            "127730/127730 [==============================] - 8s 63us/sample - loss: 0.6331 - acc: 0.6552\n",
            "loss: 0.6330710971587827\n",
            "acc: 0.65524155\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YCh-jwAJ7-_r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "11351d67-0012-49c5-ac01-a370ff479ca8"
      },
      "source": [
        "train_diff_model(data_path=r\"dataset/classifier_data_ccpg1.pkl\", \n",
        "                 res_path=\"./models\", model_name=\"150cpg\", model_path=\"temp_model\",\n",
        "                 input_len=150, num_epoch=20, batchsize=64, number_of_folds=2)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "creating model\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input (InputLayer)           [(None, 150, 4)]          0         \n",
            "_________________________________________________________________\n",
            "conv1 (Conv1D)               (None, 144, 90)           2610      \n",
            "_________________________________________________________________\n",
            "left_pool1 (MaxPooling1D)    (None, 71, 90)            0         \n",
            "_________________________________________________________________\n",
            "left_drop1 (Dropout)         (None, 71, 90)            0         \n",
            "_________________________________________________________________\n",
            "conv_merged (Conv1D)         (None, 67, 100)           45100     \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 12, 100)           0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 12, 100)           0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 1200)              0         \n",
            "_________________________________________________________________\n",
            "hidden1 (Dense)              (None, 250)               300250    \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 1)                 251       \n",
            "=================================================================\n",
            "Total params: 348,211\n",
            "Trainable params: 348,211\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "compiling model\n",
            "loading data\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fitting the model\n",
            "Using fold 0/2\n",
            "Train on 520739 samples, validate on 520739 samples\n",
            "Epoch 1/20\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.58957, saving model to temp_model\n",
            "520739/520739 - 52s - loss: 0.6063 - acc: 0.6750 - val_loss: 0.5896 - val_acc: 0.6908\n",
            "Epoch 2/20\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.58957\n",
            "520739/520739 - 52s - loss: 0.5934 - acc: 0.6864 - val_loss: 0.5919 - val_acc: 0.6924\n",
            "Epoch 3/20\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.58957 to 0.58816, saving model to temp_model\n",
            "520739/520739 - 52s - loss: 0.5901 - acc: 0.6890 - val_loss: 0.5882 - val_acc: 0.6940\n",
            "Epoch 4/20\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.58816 to 0.58655, saving model to temp_model\n",
            "520739/520739 - 53s - loss: 0.5880 - acc: 0.6915 - val_loss: 0.5865 - val_acc: 0.6949\n",
            "Epoch 5/20\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.58655 to 0.58373, saving model to temp_model\n",
            "520739/520739 - 52s - loss: 0.5865 - acc: 0.6925 - val_loss: 0.5837 - val_acc: 0.6961\n",
            "Epoch 6/20\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.58373 to 0.58233, saving model to temp_model\n",
            "520739/520739 - 52s - loss: 0.5850 - acc: 0.6932 - val_loss: 0.5823 - val_acc: 0.6971\n",
            "Epoch 7/20\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.58233\n",
            "520739/520739 - 52s - loss: 0.5836 - acc: 0.6943 - val_loss: 0.5855 - val_acc: 0.6970\n",
            "Epoch 8/20\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.58233\n",
            "520739/520739 - 52s - loss: 0.5825 - acc: 0.6947 - val_loss: 0.5826 - val_acc: 0.6976\n",
            "Epoch 9/20\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.58233 to 0.58068, saving model to temp_model\n",
            "520739/520739 - 52s - loss: 0.5816 - acc: 0.6962 - val_loss: 0.5807 - val_acc: 0.6984\n",
            "Epoch 10/20\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.58068\n",
            "520739/520739 - 53s - loss: 0.5807 - acc: 0.6968 - val_loss: 0.5816 - val_acc: 0.6981\n",
            "Epoch 11/20\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.58068\n",
            "520739/520739 - 52s - loss: 0.5798 - acc: 0.6977 - val_loss: 0.5820 - val_acc: 0.6974\n",
            "Epoch 12/20\n",
            "\n",
            "Epoch 00012: val_loss improved from 0.58068 to 0.58026, saving model to temp_model\n",
            "520739/520739 - 52s - loss: 0.5787 - acc: 0.6980 - val_loss: 0.5803 - val_acc: 0.6996\n",
            "Epoch 13/20\n",
            "\n",
            "Epoch 00013: val_loss improved from 0.58026 to 0.57993, saving model to temp_model\n",
            "520739/520739 - 52s - loss: 0.5781 - acc: 0.6989 - val_loss: 0.5799 - val_acc: 0.6993\n",
            "Epoch 14/20\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 0.57993\n",
            "520739/520739 - 52s - loss: 0.5775 - acc: 0.6994 - val_loss: 0.5805 - val_acc: 0.7006\n",
            "Epoch 15/20\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 0.57993\n",
            "520739/520739 - 52s - loss: 0.5771 - acc: 0.6995 - val_loss: 0.5817 - val_acc: 0.6992\n",
            "Epoch 16/20\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.57993\n",
            "520739/520739 - 52s - loss: 0.5767 - acc: 0.7001 - val_loss: 0.5802 - val_acc: 0.7010\n",
            "Epoch 17/20\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 0.57993\n",
            "520739/520739 - 52s - loss: 0.5759 - acc: 0.7007 - val_loss: 0.5801 - val_acc: 0.7003\n",
            "Epoch 18/20\n",
            "\n",
            "Epoch 00018: val_loss improved from 0.57993 to 0.57755, saving model to temp_model\n",
            "520739/520739 - 52s - loss: 0.5757 - acc: 0.7004 - val_loss: 0.5775 - val_acc: 0.7013\n",
            "Epoch 19/20\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 0.57755\n",
            "520739/520739 - 51s - loss: 0.5749 - acc: 0.7017 - val_loss: 0.5779 - val_acc: 0.7011\n",
            "Epoch 20/20\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.57755\n",
            "520739/520739 - 51s - loss: 0.5745 - acc: 0.7018 - val_loss: 0.5780 - val_acc: 0.7015\n",
            "Using fold 1/2\n",
            "Train on 520739 samples, validate on 520739 samples\n",
            "Epoch 1/20\n",
            "\n",
            "Epoch 00001: val_loss improved from 0.57755 to 0.57340, saving model to temp_model\n",
            "520739/520739 - 51s - loss: 0.5825 - acc: 0.6954 - val_loss: 0.5734 - val_acc: 0.7059\n",
            "Epoch 2/20\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.57340\n",
            "520739/520739 - 52s - loss: 0.5806 - acc: 0.6968 - val_loss: 0.5741 - val_acc: 0.7044\n",
            "Epoch 3/20\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.57340 to 0.57113, saving model to temp_model\n",
            "520739/520739 - 52s - loss: 0.5796 - acc: 0.6975 - val_loss: 0.5711 - val_acc: 0.7056\n",
            "Epoch 4/20\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 0.57113\n",
            "520739/520739 - 52s - loss: 0.5781 - acc: 0.6992 - val_loss: 0.5768 - val_acc: 0.7058\n",
            "Epoch 5/20\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 0.57113\n",
            "520739/520739 - 52s - loss: 0.5775 - acc: 0.6993 - val_loss: 0.5744 - val_acc: 0.7052\n",
            "Epoch 6/20\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.57113\n",
            "520739/520739 - 51s - loss: 0.5770 - acc: 0.6998 - val_loss: 0.5738 - val_acc: 0.7055\n",
            "Epoch 7/20\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.57113\n",
            "520739/520739 - 51s - loss: 0.5757 - acc: 0.7007 - val_loss: 0.5740 - val_acc: 0.7042\n",
            "Epoch 8/20\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.57113\n",
            "520739/520739 - 52s - loss: 0.5754 - acc: 0.7011 - val_loss: 0.5728 - val_acc: 0.7059\n",
            "Epoch 00008: early stopping\n",
            "saving the model\n",
            "testing the model\n",
            "127730/127730 [==============================] - 8s 60us/sample - loss: 0.6265 - acc: 0.6548\n",
            "loss: 0.6265485964954053\n",
            "acc: 0.6548031\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}