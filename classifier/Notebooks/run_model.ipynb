{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"run_model- 030820.ipynb","provenance":[{"file_id":"1qysG6N3-gJJVB6B7BHO3zuP-0sCnDUOr","timestamp":1596352204324},{"file_id":"1ziwyTEY4r7YvqKNegyQMKPHy1_Szf20R","timestamp":1595938496751}],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"d29_mG9z6PXb","colab_type":"text"},"source":["Train a model to predict complete loss of methylation or partial loss using a sequence"]},{"cell_type":"code","metadata":{"id":"1wz-ud5Hav1O","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":144},"executionInfo":{"status":"ok","timestamp":1596606295042,"user_tz":-180,"elapsed":29894,"user":{"displayName":"dror bar","photoUrl":"","userId":"08597478424783230611"}},"outputId":"c650c2e3-9f96-40af-b6f8-86cbf0c2915d"},"source":["from google.colab import drive\n","drive.mount('/gdrive')\n","%cd /gdrive "],"execution_count":2,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /gdrive\n","/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vjO8Tu5MbI-0","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1596606295079,"user_tz":-180,"elapsed":29904,"user":{"displayName":"dror bar","photoUrl":"","userId":"08597478424783230611"}},"outputId":"3c1f1646-8edf-453d-d418-2fb1e3e79375"},"source":["cd /gdrive/My\\ Drive/nn "],"execution_count":3,"outputs":[{"output_type":"stream","text":["/gdrive/My Drive/nn\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5BI8sNFMb0Lp","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":53},"executionInfo":{"status":"ok","timestamp":1596606302540,"user_tz":-180,"elapsed":37348,"user":{"displayName":"dror bar","photoUrl":"","userId":"08597478424783230611"}},"outputId":"117c0829-0dd8-49bf-dc73-b0f4f9bedbda"},"source":["%tensorflow_version 1.x\n","import argparse\n","import os\n","import pickle\n","import sys\n","import glob\n","\n","import numpy as np\n","\n","np.random.seed(7)  # for reproducibility\n","\n","import tensorflow as tf\n","tf.random.set_random_seed(5005)\n","\n","from sklearn.model_selection import train_test_split, KFold\n","from sklearn.utils import class_weight\n","\n","\n","from tensorflow.python.keras.models import Model, load_model\n","from tensorflow.python.keras.layers import Input\n","from tensorflow.python.keras.layers import Dense, Flatten, Dropout\n","from tensorflow.python.keras.layers.convolutional import Conv1D\n","from tensorflow.python.keras.layers.pooling import MaxPooling1D\n","from tensorflow.python.keras.layers.pooling import AveragePooling1D\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.python.keras.callbacks import ModelCheckpoint, EarlyStopping\n","import tensorflow.python.keras.backend as K\n","from keras import regularizers\n","from tensorflow.python.keras.utils import plot_model \n","\n","sys.path.append(\".\")\n","import utils\n","from utils import precision, recall_TP, load_train_validate_test_data, recall_TN, precision_N\n","\n","l2_lam = 5e-07 \n","l1_lam = 1e-08 "],"execution_count":4,"outputs":[{"output_type":"stream","text":["TensorFlow 1.x selected.\n"],"name":"stdout"},{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"lHcO6wobeAjx","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596606302558,"user_tz":-180,"elapsed":37354,"user":{"displayName":"dror bar","photoUrl":"","userId":"08597478424783230611"}}},"source":["def train_model_on_fold(x_train, y_train, x_test,y_test, input_len,\n","                        num_epoch, batchsize, func,model_path):\n","  \"\"\"\n","  Train a model to using the train data to predict the test data\n","  :param x_train: The train dataset \n","  :param y_train: The train labels\n","  :param x_test: The test dataset\n","  :param y_test: The test labels\n","  :param input_len: The length of the input\n","  :param num_epoch: Number of epoches \n","  :param batchsize: The batchsize \n","  :param func: The model function to use \n","  :param model_path: The path to save the model from run to run\n","  :return: The model after fitting\n","  \"\"\"\n","  model = func(input_len)\n","  adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=1e-6)\n","  model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy', recall_TP,recall_TN])\n","  checkpointer = ModelCheckpoint(filepath=model_path, verbose=1, save_best_only=True)\n","  earlystopper = EarlyStopping(monitor='val_loss', patience=5, verbose=2)\n","    \n","  print('fitting the model')          \n","  sample_weights = class_weight.compute_sample_weight('balanced', y_train)\n","\n","  history = model.fit(x_train, y_train, epochs=num_epoch, batch_size=batchsize,\n","                      validation_data=(x_test, y_test), verbose=1,\n","                      callbacks=[checkpointer, earlystopper, ], sample_weight=sample_weights)\n","  return model"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"hy29UlwGoN35","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596606302563,"user_tz":-180,"elapsed":37347,"user":{"displayName":"dror bar","photoUrl":"","userId":"08597478424783230611"}}},"source":["def sequence_model(input_len):\n","  \"\"\"\n","  Buld a model to predict a sequence information \n","  :param input_len: The length of the input\n","  \"\"\"\n","  K.clear_session()\n","  tf.random.set_random_seed(5005)\n","\n","  input_node = Input(shape=(input_len, 4), name=\"input\")\n","  conv1 = Conv1D(filters=90, kernel_size=3, padding='valid', activation=\"relu\", name=\"conv1\",kernel_regularizer=regularizers.l2(l2_lam))(input_node)\n","  pool1 = MaxPooling1D(pool_size=2, strides=1, name=\"pool1\")(conv1)\n","  drop1 = Dropout(0.25, name=\"drop1\")(pool1)\n","\n","  conv2 = Conv1D(filters=100, kernel_size=5, padding='valid', activation=\"relu\", name=\"conv2\", kernel_regularizer=regularizers.l2(l2_lam))(drop1)\n","  pool2 = MaxPooling1D(pool_size=2, strides=1)(conv2)\n","  drop2 = Dropout(0.25)(pool2)\n","  flat = Flatten()(drop2)\n","\n","  hidden1 = Dense(500, activation='relu', name=\"hidden1\",kernel_regularizer=regularizers.l1(l1_lam))(flat)\n","  drop3 = Dropout(0.5)(hidden1)\n","  hidden2 = Dense(250, activation='relu', name=\"hidden2\",kernel_regularizer=regularizers.l1(l1_lam))(drop3)\n","\n","  output = Dense(1, activation='sigmoid', name=\"output\")(hidden2)\n","  model = Model(inputs=[input_node], outputs=output)\n","\n","  return model"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"1Qi9WBFs-vub","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596606302566,"user_tz":-180,"elapsed":37340,"user":{"displayName":"dror bar","photoUrl":"","userId":"08597478424783230611"}}},"source":["def train_model(data_path, model_folder=\"./models/folds_models\", temp_model_folder=\"./models/temp/weight.h5\", input_len=150, number_of_folds=5):\n","  \"\"\"\n","  Train a model or x models using the cross validation \n","  :param data_path: The path for the dataset\n","  :param model_folder: The final folder to save the models\n","  :param temp_model_folder: A folder to save the models while running\n","  :param input_len: The length of the input\n","  :param number_of_folds: Number of fold to use for the model\n","  :return: The model if we used 1 model(1 fold) or None if more \n","  \"\"\"\n","\n","  print('loading data')\n","  x_train_list, y_train_list, x_valid_list, y_valid_list, x_test_seq, y_test = load_train_validate_test_data(data_path, input_len, kfold=number_of_folds)\n","\n","  models_path = []\n","  acc_per_fold = []\n","  loss_per_fold = []\n","\n","  for fold_num in range(len(x_train_list)):\n","    print(\"Using fold %s/%s\" %(fold_num+1, number_of_folds))\n","    x_train_seq = x_train_list[fold_num]\n","    y_train = y_train_list[fold_num]\n","    x_valid_seq = x_valid_list[fold_num]\n","    y_valid = y_valid_list[fold_num]\n","\n","    temp_model_file = model_path  = os.path.join(model_folder, \"fold%s.h5\" %fold_num)\n","\n","    model = train_model_on_fold(x_train_seq, y_train, x_valid_seq, y_valid, model_path=temp_model_folder, \n","                            input_len=150, num_epoch=20, batchsize=128, func = sequence_model)\n","    \n","    if fold_num == 0:\n","      print(model.summary())\n","      plot_model(model, show_shapes=True, show_layer_names=True,rankdir=\"TB\")\n","\n","    print(\"Finish training fold %d\" % (fold_num+1))\n","    print('testing the model')\n","    score = model.evaluate(x_test_seq, y_test)\n","\n","    for i in range(len(model.metrics_names)):\n","        print(str(model.metrics_names[i]) + \": \" + str(score[i]))\n","\n","    acc_per_fold.append(score[1] * 100)\n","    loss_per_fold.append(score[0])\n","    models_path.append(model_path)\n","\n","    model.save(model_path)\n","\n","  print('Average scores for all folds:')\n","  print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n","  print(f'> Loss: {np.mean(loss_per_fold)}')\n","\n","  if number_of_folds == 1:\n","    return model\n","  \n","  return None "],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZByqKY638_LK","colab_type":"code","colab":{}},"source":["def load_models(models_folder):\n","  \"\"\"\n","  Load the different models from the folder\n","  :param models_folder: path to the folder with models \n","  \"\"\"\n","  models_paths = glob.glob(os.path.join(models_folder, \"*.h5\"))\n","\n","  models = [load_model(model_path, custom_objects={'recall_TP': recall_TP,'recall_TN': recall_TN }) for model_path in models_paths]\n","  return models\n","\n","\n","def get_scores(models, x_test, y_test):\n","  \"\"\"\n","  Calculate and print the scores (accuracy and loss) for every model and the accuracy value\n","  :param models: A list of loaded models \n","  :param x_test: The dataset \n","  :param y_test: The real labels\n","  :return A list of accuracy scores and loss scores per fold\n","  \"\"\"\n","  acc_per_fold =[]\n","  loss_per_fold = []\n","\n","  for model in models:\n","    score = model.evaluate(x_test_seq, y_test)\n","    acc_per_fold.append(score[1] * 100)\n","    loss_per_fold.append(score[0])\n","\n","  print('Average scores for all folds:')\n","  print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n","  print(f'> Loss: {np.mean(loss_per_fold)}')\n","  return acc_per_fold, loss_per_fold\n","\n","def predict(models, x, use_majority=True):\n","  \"\"\"\n","  Predict the output of x using the different models that were provided, if use_majority=True we use majority vote, if False we use Average vote\n","  :param models: A list of loaded models \n","  :param x: The dataset to predict on\n","  :param use_majority:if use_majority=True we use majority vote, if False we use Average vote\n","  :return the prediction for labels \n","  \"\"\"\n","  y_pred = np.zeros(shape=(x.shape[0], len(models)))\n","  \n","  for i in range(len(models)):\n","    if use_majority:\n","      model_prediciton = np.round(models[i].predict(x))    \n","    else:\n","      model_prediciton = models[i].predict(x)\n","\n","    y_pred[:,i] = model_prediciton.reshape(model_prediciton.shape[0])\n","    \n","  return np.round(np.mean(y_pred, axis=1))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xvGZ7hsF6cP2","colab_type":"text"},"source":["Run the different functions"]},{"cell_type":"code","metadata":{"id":"iR06nRVA35mX","colab_type":"code","colab":{}},"source":["# Train the NN on the scWGBS data using 5 folds \n","zhou_all_data = r\"dataset/zhou_all.pkl\"\n","zhou_solo_data = r\"dataset/zhou_solo.pkl\"\n","scgwbs_data = r\"dataset/scwgbs_solo.pkl\"\n","models_folder=\"./models/folds_models\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XknwN_9VNmQ8","colab_type":"code","colab":{}},"source":["# Train\n","model = train_model(data_path=data_path, model_folder=models_folder, temp_model_folder=\"./models/temp/weight.h5\", input_len=150, number_of_folds=2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"suzJWxJ4SWb0","colab_type":"code","colab":{}},"source":["# Test\n","_,_,_,_, x_test_seq, y_test = load_train_validate_test_data(path_to_data=scgwbs_data, input_len=150, kfold=1, only_test=True)\n","\n","models = load_models(models_folder)\n","_, _ = get_scores(models,x_test_seq, y_test)\n","\n","# Get global prediction\n","y_pred = predict(models, x_test_seq)\n","\n","# Get accuracy of combined model\n","diff = y_test - y_pred\n","good_predictions = np.sum(diff == 0)\n","print(\"Accuracy using majority vote: %s\" %(good_predictions / y_test.shape[0] * 100))"],"execution_count":null,"outputs":[]}]}