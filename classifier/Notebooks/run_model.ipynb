{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "run_model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wz-ud5Hav1O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "cb8360d6-852b-4239-f579-7fe46438f40c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "%cd /gdrive "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive\n",
            "/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjO8Tu5MbI-0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e433233f-4f32-4f40-83d9-29cdfd642664"
      },
      "source": [
        "cd /gdrive/My\\ Drive/nn "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/gdrive/My Drive/nn\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5BI8sNFMb0Lp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "94c1bba0-9c28-40db-8184-9f1883c7a3b9"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import argparse\n",
        "import os\n",
        "import pickle\n",
        "import sys\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "np.random.seed(7)  # for reproducibility\n",
        "\n",
        "import tensorflow as tf\n",
        "tf.random.set_random_seed(5005)\n",
        "\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.utils import class_weight\n",
        "\n",
        "\n",
        "from tensorflow.python.keras.models import Model, load_model\n",
        "from tensorflow.python.keras.layers import Input\n",
        "from tensorflow.python.keras.layers import Dense, Flatten, Dropout\n",
        "from tensorflow.python.keras.layers.convolutional import Conv1D\n",
        "from tensorflow.python.keras.layers.pooling import MaxPooling1D\n",
        "from tensorflow.python.keras.layers.pooling import AveragePooling1D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.python.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "import tensorflow.python.keras.backend as K\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras import regularizers\n",
        "\n",
        "import matplotlib as mpl\n",
        "\n",
        "mpl.use('Agg')\n",
        "import utils\n",
        "sys.path.append(\".\")\n",
        "\n",
        "import importlib\n",
        "importlib.reload(utils)\n",
        "\n",
        "from utils import precision, recall_TP, load_data_merged, recall_TN, precision_N\n",
        "\n",
        "l2_lam = 5e-07 \n",
        "l1_lam = 1e-08 "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lHcO6wobeAjx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_diff_model(data_path, res_path, model_name, input_len,\n",
        "                     num_epoch, batchsize, func,model_path=\"./weights.hdf5\", \n",
        "                     number_of_folds=1, save=True):\n",
        "    print('creating model')\n",
        "    model = func(input_len)\n",
        "    print('compiling model')\n",
        "    adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=1e-6)\n",
        "\n",
        "    model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy', recall_TP,recall_TN])\n",
        "    checkpointer = ModelCheckpoint(filepath=model_path, verbose=1, save_best_only=True)\n",
        "    earlystopper = EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
        "\n",
        "    print('loading data')\n",
        "    x_train_list, y_train_list, x_valid_list, y_valid_list, x_test_seq, y_test = load_data_merged(data_path, input_len, kfold=number_of_folds)\n",
        "    \n",
        "    print(\"calculating weights\")\n",
        "    if number_of_folds != 1:\n",
        "      print(\"the class weights won't work\")\n",
        "\n",
        "    print('fitting the model')\n",
        "    for i in range(len(x_train_list)):\n",
        "      print(\"Using fold %s/%s\" %(i+1, number_of_folds))\n",
        "      x_train_seq = x_train_list[i]\n",
        "      y_train = y_train_list[i]\n",
        "      x_valid_seq = x_valid_list[i]\n",
        "      y_valid = y_valid_list[i]\n",
        "      sample_weights = class_weight.compute_sample_weight('balanced', y_train)\n",
        "\n",
        "\n",
        "      history = model.fit(x_train_seq, y_train, epochs=num_epoch, batch_size=batchsize,\n",
        "                          validation_data=(x_valid_seq, y_valid), verbose=1,\n",
        "                          callbacks=[checkpointer, earlystopper, ], sample_weight=sample_weights)  # tb])\n",
        "    \n",
        "    print(\"Finish training\")\n",
        "    if save:\n",
        "      print('saving the model')\n",
        "      model.save(os.path.join(res_path, model_name + \".h5\"))\n",
        "\n",
        "    print('testing the model')\n",
        "    score = model.evaluate(x_test_seq, y_test)\n",
        "\n",
        "    for i in range(len(model.metrics_names)):\n",
        "        print(str(model.metrics_names[i]) + \": \" + str(score[i]))\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-Fzb9sEeUub",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model4 = train_diff_model(data_path=r\"dataset/solo_test_with_crc10_var_0.05.pkl\", \n",
        "                 res_path=\"./models\", model_name=\"model_2nd_dense_dropout\", model_path=\"./models/temp/1\",\n",
        "                 input_len=150, num_epoch=20, batchsize=128, number_of_folds=1,save=False, func = model26_another_chance_for_2nd_dense_more_dropout)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2OsP3qp219vc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model4.save(os.path.join(\"./models\", \"deepripe\" + \".h5\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MibqfF61qzF_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "57b3f87a-dcac-4157-b888-313131bd80d1"
      },
      "source": [
        "model4 = train_diff_model(data_path=r\"dataset/solo_test_with_crc10_var_0.05.pkl\", \n",
        "                 res_path=\"./models\", model_name=\"model26_another_chance_for_2nd_dense_more_dropout_no_conv0\", model_path=\"./models/temp/2\",\n",
        "                 input_len=150, num_epoch=20, batchsize=128, number_of_folds=1,save=False, func = model26_another_chance_for_2nd_dense_more_dropout_no_conv0)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "creating model\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input (InputLayer)           [(None, 150, 4)]          0         \n",
            "_________________________________________________________________\n",
            "conv1 (Conv1D)               (None, 148, 90)           1170      \n",
            "_________________________________________________________________\n",
            "pool1 (MaxPooling1D)         (None, 147, 90)           0         \n",
            "_________________________________________________________________\n",
            "drop1 (Dropout)              (None, 147, 90)           0         \n",
            "_________________________________________________________________\n",
            "conv2 (Conv1D)               (None, 143, 100)          45100     \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 142, 100)          0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 142, 100)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 14200)             0         \n",
            "_________________________________________________________________\n",
            "hidden1 (Dense)              (None, 500)               7100500   \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 500)               0         \n",
            "_________________________________________________________________\n",
            "hidden2 (Dense)              (None, 250)               125250    \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 1)                 251       \n",
            "=================================================================\n",
            "Total params: 7,272,271\n",
            "Trainable params: 7,272,271\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "compiling model\n",
            "loading data\n",
            "calculating weights\n",
            "fitting the model\n",
            "Using fold 1/1\n",
            "Train on 583680 samples, validate on 145920 samples\n",
            "Epoch 1/20\n",
            "582912/583680 [============================>.] - ETA: 0s - loss: 0.6063 - acc: 0.6598 - recall_TP: 0.6808 - recall_TN: 0.6497\n",
            "Epoch 00001: val_loss improved from inf to 0.57386, saving model to ./models/temp/2\n",
            "583680/583680 [==============================] - 44s 75us/sample - loss: 0.6063 - acc: 0.6598 - recall_TP: 0.6808 - recall_TN: 0.6497 - val_loss: 0.5739 - val_acc: 0.7039 - val_recall_TP: 0.7626 - val_recall_TN: 0.6753\n",
            "Epoch 2/20\n",
            "583168/583680 [============================>.] - ETA: 0s - loss: 0.5707 - acc: 0.7058 - recall_TP: 0.7259 - recall_TN: 0.6963\n",
            "Epoch 00002: val_loss improved from 0.57386 to 0.53733, saving model to ./models/temp/2\n",
            "583680/583680 [==============================] - 43s 74us/sample - loss: 0.5707 - acc: 0.7058 - recall_TP: 0.7260 - recall_TN: 0.6962 - val_loss: 0.5373 - val_acc: 0.7221 - val_recall_TP: 0.7347 - val_recall_TN: 0.7159\n",
            "Epoch 3/20\n",
            "583424/583680 [============================>.] - ETA: 0s - loss: 0.5634 - acc: 0.7111 - recall_TP: 0.7333 - recall_TN: 0.7003\n",
            "Epoch 00003: val_loss did not improve from 0.53733\n",
            "583680/583680 [==============================] - 42s 72us/sample - loss: 0.5634 - acc: 0.7111 - recall_TP: 0.7334 - recall_TN: 0.7003 - val_loss: 0.5582 - val_acc: 0.7153 - val_recall_TP: 0.7672 - val_recall_TN: 0.6897\n",
            "Epoch 4/20\n",
            "583296/583680 [============================>.] - ETA: 0s - loss: 0.5582 - acc: 0.7133 - recall_TP: 0.7426 - recall_TN: 0.6991\n",
            "Epoch 00004: val_loss did not improve from 0.53733\n",
            "583680/583680 [==============================] - 42s 73us/sample - loss: 0.5582 - acc: 0.7133 - recall_TP: 0.7426 - recall_TN: 0.6991 - val_loss: 0.5577 - val_acc: 0.7244 - val_recall_TP: 0.7531 - val_recall_TN: 0.7105\n",
            "Epoch 5/20\n",
            "583424/583680 [============================>.] - ETA: 0s - loss: 0.5539 - acc: 0.7168 - recall_TP: 0.7451 - recall_TN: 0.7031\n",
            "Epoch 00005: val_loss did not improve from 0.53733\n",
            "583680/583680 [==============================] - 42s 72us/sample - loss: 0.5539 - acc: 0.7168 - recall_TP: 0.7451 - recall_TN: 0.7031 - val_loss: 0.5590 - val_acc: 0.7163 - val_recall_TP: 0.7851 - val_recall_TN: 0.6826\n",
            "Epoch 6/20\n",
            "583296/583680 [============================>.] - ETA: 0s - loss: 0.5495 - acc: 0.7206 - recall_TP: 0.7497 - recall_TN: 0.7065\n",
            "Epoch 00006: val_loss did not improve from 0.53733\n",
            "583680/583680 [==============================] - 42s 72us/sample - loss: 0.5495 - acc: 0.7206 - recall_TP: 0.7497 - recall_TN: 0.7065 - val_loss: 0.5373 - val_acc: 0.7372 - val_recall_TP: 0.7273 - val_recall_TN: 0.7422\n",
            "Epoch 7/20\n",
            "583552/583680 [============================>.] - ETA: 0s - loss: 0.5454 - acc: 0.7240 - recall_TP: 0.7508 - recall_TN: 0.7110\n",
            "Epoch 00007: val_loss did not improve from 0.53733\n",
            "583680/583680 [==============================] - 42s 72us/sample - loss: 0.5454 - acc: 0.7240 - recall_TP: 0.7508 - recall_TN: 0.7110 - val_loss: 0.5430 - val_acc: 0.7223 - val_recall_TP: 0.7712 - val_recall_TN: 0.6984\n",
            "Epoch 00007: early stopping\n",
            "Finish training\n",
            "testing the model\n",
            "84468/84468 [==============================] - 5s 63us/sample - loss: 0.5704 - acc: 0.7011 - recall_TP: 0.7036 - recall_TN: 0.7275\n",
            "loss: 0.5704132503799774\n",
            "acc: 0.7010939\n",
            "recall_TP: 0.70358306\n",
            "recall_TN: 0.7274847\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJyqYoO9SYn6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2354e481-df47-4e85-d7ca-9574b1df596c"
      },
      "source": [
        "model3 = train_diff_model(data_path=r\"dataset/solo_test_with_crc10_var_0.05.pkl\", \n",
        "                 res_path=\"./models\", model_name=\"deepripe_model\", model_path=\"./models/temp/3\",\n",
        "                 input_len=150, num_epoch=20, batchsize=128, number_of_folds=1,save=False, func = deepripe_orig)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "creating model\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "left_input (InputLayer)      [(None, 150, 4)]          0         \n",
            "_________________________________________________________________\n",
            "left_conv1 (Conv1D)          (None, 144, 90)           2610      \n",
            "_________________________________________________________________\n",
            "left_pool1 (MaxPooling1D)    (None, 71, 90)            0         \n",
            "_________________________________________________________________\n",
            "left_drop1 (Dropout)         (None, 71, 90)            0         \n",
            "_________________________________________________________________\n",
            "conv_merged (Conv1D)         (None, 67, 100)           45100     \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 12, 100)           0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 12, 100)           0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 1200)              0         \n",
            "_________________________________________________________________\n",
            "hidden1 (Dense)              (None, 250)               300250    \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 1)                 251       \n",
            "=================================================================\n",
            "Total params: 348,211\n",
            "Trainable params: 348,211\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "compiling model\n",
            "loading data\n",
            "calculating weights\n",
            "fitting the model\n",
            "Using fold 1/1\n",
            "Train on 583680 samples, validate on 145920 samples\n",
            "Epoch 1/20\n",
            "583296/583680 [============================>.] - ETA: 0s - loss: 0.6010 - acc: 0.6784 - recall_TP: 0.6748 - recall_TN: 0.6803\n",
            "Epoch 00001: val_loss improved from inf to 0.56794, saving model to ./models/temp/3\n",
            "583680/583680 [==============================] - 25s 43us/sample - loss: 0.6010 - acc: 0.6785 - recall_TP: 0.6748 - recall_TN: 0.6803 - val_loss: 0.5679 - val_acc: 0.7037 - val_recall_TP: 0.7006 - val_recall_TN: 0.7052\n",
            "Epoch 2/20\n",
            "583552/583680 [============================>.] - ETA: 0s - loss: 0.5830 - acc: 0.6964 - recall_TP: 0.7019 - recall_TN: 0.6938\n",
            "Epoch 00002: val_loss improved from 0.56794 to 0.56031, saving model to ./models/temp/3\n",
            "583680/583680 [==============================] - 25s 42us/sample - loss: 0.5830 - acc: 0.6964 - recall_TP: 0.7019 - recall_TN: 0.6938 - val_loss: 0.5603 - val_acc: 0.7132 - val_recall_TP: 0.6872 - val_recall_TN: 0.7258\n",
            "Epoch 3/20\n",
            "582912/583680 [============================>.] - ETA: 0s - loss: 0.5792 - acc: 0.6994 - recall_TP: 0.7057 - recall_TN: 0.6964\n",
            "Epoch 00003: val_loss did not improve from 0.56031\n",
            "583680/583680 [==============================] - 24s 41us/sample - loss: 0.5792 - acc: 0.6994 - recall_TP: 0.7057 - recall_TN: 0.6964 - val_loss: 0.5734 - val_acc: 0.7049 - val_recall_TP: 0.7133 - val_recall_TN: 0.7008\n",
            "Epoch 4/20\n",
            "583168/583680 [============================>.] - ETA: 0s - loss: 0.5771 - acc: 0.6998 - recall_TP: 0.7099 - recall_TN: 0.6948\n",
            "Epoch 00004: val_loss improved from 0.56031 to 0.54760, saving model to ./models/temp/3\n",
            "583680/583680 [==============================] - 25s 43us/sample - loss: 0.5771 - acc: 0.6998 - recall_TP: 0.7099 - recall_TN: 0.6948 - val_loss: 0.5476 - val_acc: 0.7218 - val_recall_TP: 0.6656 - val_recall_TN: 0.7496\n",
            "Epoch 5/20\n",
            "582400/583680 [============================>.] - ETA: 0s - loss: 0.5751 - acc: 0.7011 - recall_TP: 0.7118 - recall_TN: 0.6960\n",
            "Epoch 00005: val_loss did not improve from 0.54760\n",
            "583680/583680 [==============================] - 24s 41us/sample - loss: 0.5751 - acc: 0.7011 - recall_TP: 0.7118 - recall_TN: 0.6960 - val_loss: 0.5654 - val_acc: 0.7105 - val_recall_TP: 0.7078 - val_recall_TN: 0.7118\n",
            "Epoch 6/20\n",
            "582528/583680 [============================>.] - ETA: 0s - loss: 0.5738 - acc: 0.7021 - recall_TP: 0.7121 - recall_TN: 0.6971\n",
            "Epoch 00006: val_loss did not improve from 0.54760\n",
            "583680/583680 [==============================] - 25s 42us/sample - loss: 0.5738 - acc: 0.7021 - recall_TP: 0.7121 - recall_TN: 0.6971 - val_loss: 0.5635 - val_acc: 0.7121 - val_recall_TP: 0.7016 - val_recall_TN: 0.7171\n",
            "Epoch 7/20\n",
            "582656/583680 [============================>.] - ETA: 0s - loss: 0.5727 - acc: 0.7040 - recall_TP: 0.7127 - recall_TN: 0.6998\n",
            "Epoch 00007: val_loss did not improve from 0.54760\n",
            "583680/583680 [==============================] - 24s 41us/sample - loss: 0.5727 - acc: 0.7040 - recall_TP: 0.7127 - recall_TN: 0.6997 - val_loss: 0.5722 - val_acc: 0.7031 - val_recall_TP: 0.7298 - val_recall_TN: 0.6898\n",
            "Epoch 8/20\n",
            "583040/583680 [============================>.] - ETA: 0s - loss: 0.5717 - acc: 0.7034 - recall_TP: 0.7142 - recall_TN: 0.6981\n",
            "Epoch 00008: val_loss did not improve from 0.54760\n",
            "583680/583680 [==============================] - 24s 42us/sample - loss: 0.5717 - acc: 0.7034 - recall_TP: 0.7142 - recall_TN: 0.6981 - val_loss: 0.5684 - val_acc: 0.7072 - val_recall_TP: 0.7238 - val_recall_TN: 0.6990\n",
            "Epoch 9/20\n",
            "583552/583680 [============================>.] - ETA: 0s - loss: 0.5701 - acc: 0.7050 - recall_TP: 0.7158 - recall_TN: 0.6996\n",
            "Epoch 00009: val_loss did not improve from 0.54760\n",
            "583680/583680 [==============================] - 24s 41us/sample - loss: 0.5701 - acc: 0.7050 - recall_TP: 0.7158 - recall_TN: 0.6996 - val_loss: 0.5712 - val_acc: 0.7057 - val_recall_TP: 0.7254 - val_recall_TN: 0.6962\n",
            "Epoch 00009: early stopping\n",
            "Finish training\n",
            "testing the model\n",
            "84468/84468 [==============================] - 5s 55us/sample - loss: 0.5936 - acc: 0.6827 - recall_TP: 0.6657 - recall_TN: 0.7201\n",
            "loss: 0.5936168210013163\n",
            "acc: 0.68270826\n",
            "recall_TP: 0.6656892\n",
            "recall_TN: 0.7201234\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9BnqSbe56sOe",
        "colab_type": "text"
      },
      "source": [
        "84468/84468 [==============================] - 8s 92us/sample - loss: 0.5735 - acc: 0.7038 - recall_TP: 0.6948 - recall_TN: 0.7374\n",
        "loss: 0.5734771836795844\n",
        "acc: 0.7038287\n",
        "recall_TP: 0.6948228\n",
        "recall_TN: 0.73737407"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "juOqJXm4Yu0o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model26_another_chance_for_2nd_dense_and_avg(input_len):\n",
        "    K.clear_session()\n",
        "    # tf.random.set_random_seed(5005)\n",
        "\n",
        "    input_node = Input(shape=(input_len, 4), name=\"input\")\n",
        "    conv0 = Conv1D(filters=90, kernel_size=1, padding='valid', activation=\"relu\", name=\"conv0\",kernel_regularizer=regularizers.l2(l2_lam))(input_node)\n",
        "    conv1 = Conv1D(filters=90, kernel_size=3, padding='valid', activation=\"relu\", name=\"conv1\",kernel_regularizer=regularizers.l2(l2_lam))(conv0)\n",
        "    pool1 = AveragePooling1D(pool_size=2, strides=1, name=\"pool1\")(conv1)\n",
        "    drop1 = Dropout(0.25, name=\"drop1\")(pool1)\n",
        "  \n",
        "    conv2 = Conv1D(filters=100, kernel_size=5, padding='valid', activation=\"relu\", name=\"conv2\", kernel_regularizer=regularizers.l2(l2_lam))(drop1)\n",
        "    pool2 = AveragePooling1D(pool_size=2, strides=1)(conv2)\n",
        "    drop2 = Dropout(0.25)(pool2)\n",
        "    flat = Flatten()(drop2)\n",
        "\n",
        "    hidden1 = Dense(500, activation='relu', name=\"hidden1\",kernel_regularizer=regularizers.l1(l1_lam))(flat)\n",
        "    drop3 = Dropout(0.25)(hidden1)\n",
        "    hidden2 = Dense(250, activation='relu', name=\"hidden2\",kernel_regularizer=regularizers.l1(l1_lam))(drop3)\n",
        "\n",
        "    output = Dense(1, activation='sigmoid', name=\"output\")(hidden2)\n",
        "    model = Model(inputs=[input_node], outputs=output)\n",
        "    print(model.summary())\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbqQQDCTYux-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model26_another_chance_for_2nd_dense_more_dropout(input_len):\n",
        "    K.clear_session()\n",
        "    # tf.random.set_random_seed(5005)\n",
        "\n",
        "    input_node = Input(shape=(input_len, 4), name=\"input\")\n",
        "    conv0 = Conv1D(filters=90, kernel_size=1, padding='valid', activation=\"relu\", name=\"conv0\",kernel_regularizer=regularizers.l2(l2_lam))(input_node)\n",
        "    conv1 = Conv1D(filters=90, kernel_size=3, padding='valid', activation=\"relu\", name=\"conv1\",kernel_regularizer=regularizers.l2(l2_lam))(conv0)\n",
        "    pool1 = MaxPooling1D(pool_size=2, strides=1, name=\"pool1\")(conv1)\n",
        "    drop1 = Dropout(0.25, name=\"drop1\")(pool1)\n",
        "  \n",
        "    conv2 = Conv1D(filters=100, kernel_size=5, padding='valid', activation=\"relu\", name=\"conv2\", kernel_regularizer=regularizers.l2(l2_lam))(drop1)\n",
        "    pool2 = MaxPooling1D(pool_size=2, strides=1)(conv2)\n",
        "    drop2 = Dropout(0.25)(pool2)\n",
        "    flat = Flatten()(drop2)\n",
        "\n",
        "    hidden1 = Dense(500, activation='relu', name=\"hidden1\",kernel_regularizer=regularizers.l1(l1_lam))(flat)\n",
        "    drop3 = Dropout(0.5)(hidden1)\n",
        "    hidden2 = Dense(250, activation='relu', name=\"hidden2\",kernel_regularizer=regularizers.l1(l1_lam))(drop3)\n",
        "\n",
        "    output = Dense(1, activation='sigmoid', name=\"output\")(hidden2)\n",
        "    model = Model(inputs=[input_node], outputs=output)\n",
        "    print(model.summary())\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hy29UlwGoN35",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model26_another_chance_for_2nd_dense_more_dropout_no_conv0(input_len):\n",
        "    K.clear_session()\n",
        "    # tf.random.set_random_seed(5005)\n",
        "\n",
        "    input_node = Input(shape=(input_len, 4), name=\"input\")\n",
        "    conv1 = Conv1D(filters=90, kernel_size=3, padding='valid', activation=\"relu\", name=\"conv1\",kernel_regularizer=regularizers.l2(l2_lam))(input_node)\n",
        "    pool1 = MaxPooling1D(pool_size=2, strides=1, name=\"pool1\")(conv1)\n",
        "    drop1 = Dropout(0.25, name=\"drop1\")(pool1)\n",
        "  \n",
        "    conv2 = Conv1D(filters=100, kernel_size=5, padding='valid', activation=\"relu\", name=\"conv2\", kernel_regularizer=regularizers.l2(l2_lam))(drop1)\n",
        "    pool2 = MaxPooling1D(pool_size=2, strides=1)(conv2)\n",
        "    drop2 = Dropout(0.25)(pool2)\n",
        "    flat = Flatten()(drop2)\n",
        "\n",
        "    hidden1 = Dense(500, activation='relu', name=\"hidden1\",kernel_regularizer=regularizers.l1(l1_lam))(flat)\n",
        "    drop3 = Dropout(0.5)(hidden1)\n",
        "    hidden2 = Dense(250, activation='relu', name=\"hidden2\",kernel_regularizer=regularizers.l1(l1_lam))(drop3)\n",
        "\n",
        "    output = Dense(1, activation='sigmoid', name=\"output\")(hidden2)\n",
        "    model = Model(inputs=[input_node], outputs=output)\n",
        "    print(model.summary())\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7x2m-3EYuvZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model26_another_chance_for_2nd_dense_more_filters(input_len):\n",
        "    K.clear_session()\n",
        "    # tf.random.set_random_seed(5005)\n",
        "\n",
        "    input_node = Input(shape=(input_len, 4), name=\"input\")\n",
        "    conv0 = Conv1D(filters=150, kernel_size=1, padding='valid', activation=\"relu\", name=\"conv0\",kernel_regularizer=regularizers.l2(l2_lam))(input_node)\n",
        "    conv1 = Conv1D(filters=150, kernel_size=3, padding='valid', activation=\"relu\", name=\"conv1\",kernel_regularizer=regularizers.l2(l2_lam))(conv0)\n",
        "    pool1 = MaxPooling1D(pool_size=2, strides=1, name=\"pool1\")(conv1)\n",
        "    drop1 = Dropout(0.25, name=\"drop1\")(pool1)\n",
        "  \n",
        "    conv2 = Conv1D(filters=300, kernel_size=5, padding='valid', activation=\"relu\", name=\"conv2\", kernel_regularizer=regularizers.l2(l2_lam))(drop1)\n",
        "    pool2 = MaxPooling1D(pool_size=2, strides=1)(conv2)\n",
        "    drop2 = Dropout(0.25)(pool2)\n",
        "    flat = Flatten()(drop2)\n",
        "\n",
        "    hidden1 = Dense(500, activation='relu', name=\"hidden1\",kernel_regularizer=regularizers.l1(l1_lam))(flat)\n",
        "    drop3 = Dropout(0.25)(hidden1)\n",
        "    hidden2 = Dense(250, activation='relu', name=\"hidden2\",kernel_regularizer=regularizers.l1(l1_lam))(drop3)\n",
        "\n",
        "    output = Dense(1, activation='sigmoid', name=\"output\")(hidden2)\n",
        "    model = Model(inputs=[input_node], outputs=output)\n",
        "    print(model.summary())\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SbJG8TKSqqKU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model26_another_chance_for_2nd_dense_more_dropout_and_avg(input_len):\n",
        "    K.clear_session()\n",
        "    # tf.random.set_random_seed(5005)\n",
        "\n",
        "    input_node = Input(shape=(input_len, 4), name=\"input\")\n",
        "    conv0 = Conv1D(filters=90, kernel_size=1, padding='valid', activation=\"relu\", name=\"conv0\",kernel_regularizer=regularizers.l2(l2_lam))(input_node)\n",
        "    conv1 = Conv1D(filters=90, kernel_size=3, padding='valid', activation=\"relu\", name=\"conv1\",kernel_regularizer=regularizers.l2(l2_lam))(conv0)\n",
        "    pool1 = AveragePooling1D(pool_size=2, strides=1, name=\"pool1\")(conv1)\n",
        "    drop1 = Dropout(0.25, name=\"drop1\")(pool1)\n",
        "  \n",
        "    conv2 = Conv1D(filters=100, kernel_size=5, padding='valid', activation=\"relu\", name=\"conv2\", kernel_regularizer=regularizers.l2(l2_lam))(drop1)\n",
        "    pool2 = AveragePooling1D(pool_size=2, strides=1)(conv2)\n",
        "    drop2 = Dropout(0.25)(pool2)\n",
        "    flat = Flatten()(drop2)\n",
        "\n",
        "    hidden1 = Dense(500, activation='relu', name=\"hidden1\",kernel_regularizer=regularizers.l1(l1_lam))(flat)\n",
        "    drop3 = Dropout(0.5)(hidden1)\n",
        "    hidden2 = Dense(250, activation='relu', name=\"hidden2\",kernel_regularizer=regularizers.l1(l1_lam))(drop3)\n",
        "\n",
        "    output = Dense(1, activation='sigmoid', name=\"output\")(hidden2)\n",
        "    model = Model(inputs=[input_node], outputs=output)\n",
        "    print(model.summary())\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lPBAnndLYusB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PDkrCgcz5PQL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model26_avg_pool(input_len):\n",
        "    K.clear_session()\n",
        "\n",
        "    input_node = Input(shape=(input_len, 4), name=\"input\")\n",
        "    conv0 = Conv1D(filters=90, kernel_size=1, padding='valid', activation=\"relu\", name=\"conv0\",kernel_regularizer=regularizers.l2(l2_lam))(input_node)\n",
        "    conv1 = Conv1D(filters=90, kernel_size=3, padding='valid', activation=\"relu\", name=\"conv1\",kernel_regularizer=regularizers.l2(l2_lam))(conv0)\n",
        "    pool1 = AveragePooling1D(pool_size=2, strides=1, name=\"pool1\")(conv1)\n",
        "    drop1 = Dropout(0.25, name=\"drop1\")(pool1)\n",
        "  \n",
        "    conv2 = Conv1D(filters=100, kernel_size=5, padding='valid', activation=\"relu\", name=\"conv2\",kernel_regularizer=regularizers.l2(l2_lam))(drop1)\n",
        "    pool2 = AveragePooling1D(pool_size=2, strides=1)(conv2)\n",
        "    drop2 = Dropout(0.25)(pool2)\n",
        "    flat = Flatten()(drop2)\n",
        "\n",
        "    hidden1 = Dense(500, activation='relu', name=\"hidden1\",kernel_regularizer=regularizers.l1(l1_lam))(flat)\n",
        "    output = Dense(1, activation='sigmoid', name=\"output\")(hidden1)\n",
        "    model = Model(inputs=[input_node], outputs=output)\n",
        "    print(model.summary())\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5HBP2NCg5PNh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model26(input_len):\n",
        "    K.clear_session()\n",
        "    # tf.random.set_random_seed(5005)\n",
        "\n",
        "    input_node = Input(shape=(input_len, 4), name=\"input\")\n",
        "    conv0 = Conv1D(filters=90, kernel_size=1, padding='valid', activation=\"relu\", name=\"conv0\",kernel_regularizer=regularizers.l2(l2_lam))(input_node)\n",
        "    conv1 = Conv1D(filters=90, kernel_size=3, padding='valid', activation=\"relu\", name=\"conv1\",kernel_regularizer=regularizers.l2(l2_lam))(conv0)\n",
        "    pool1 = MaxPooling1D(pool_size=2, strides=1, name=\"pool1\")(conv1)\n",
        "    drop1 = Dropout(0.25, name=\"drop1\")(pool1)\n",
        "  \n",
        "    conv2 = Conv1D(filters=100, kernel_size=5, padding='valid', activation=\"relu\", name=\"conv2\",kernel_regularizer=regularizers.l2(l2_lam))(drop1)\n",
        "    pool2 = MaxPooling1D(pool_size=2, strides=1)(conv2)\n",
        "    drop2 = Dropout(0.25)(pool2)\n",
        "    flat = Flatten()(drop2)\n",
        "\n",
        "    hidden1 = Dense(500, activation='relu', name=\"hidden1\",kernel_regularizer=regularizers.l1(l1_lam))(flat)\n",
        "    output = Dense(1, activation='sigmoid', name=\"output\")(hidden1)\n",
        "    model = Model(inputs=[input_node], outputs=output)\n",
        "    print(model.summary())\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Igcrg62fzgHo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model26_another_chance_for_2nd_dense(input_len):\n",
        "    K.clear_session()\n",
        "    # tf.random.set_random_seed(5005)\n",
        "\n",
        "    input_node = Input(shape=(input_len, 4), name=\"input\")\n",
        "    conv0 = Conv1D(filters=90, kernel_size=1, padding='valid', activation=\"relu\", name=\"conv0\",kernel_regularizer=regularizers.l2(l2_lam))(input_node)\n",
        "    conv1 = Conv1D(filters=90, kernel_size=3, padding='valid', activation=\"relu\", name=\"conv1\",kernel_regularizer=regularizers.l2(l2_lam))(conv0)\n",
        "    pool1 = MaxPooling1D(pool_size=2, strides=1, name=\"pool1\")(conv1)\n",
        "    drop1 = Dropout(0.25, name=\"drop1\")(pool1)\n",
        "  \n",
        "    conv2 = Conv1D(filters=100, kernel_size=5, padding='valid', activation=\"relu\", name=\"conv2\", kernel_regularizer=regularizers.l2(l2_lam))(drop1)\n",
        "    pool2 = MaxPooling1D(pool_size=2, strides=1)(conv2)\n",
        "    drop2 = Dropout(0.25)(pool2)\n",
        "    flat = Flatten()(drop2)\n",
        "\n",
        "    hidden1 = Dense(500, activation='relu', name=\"hidden1\",kernel_regularizer=regularizers.l1(l1_lam))(flat)\n",
        "    drop3 = Dropout(0.25)(hidden1)\n",
        "    hidden2 = Dense(250, activation='relu', name=\"hidden2\",kernel_regularizer=regularizers.l1(l1_lam))(drop3)\n",
        "\n",
        "    output = Dense(1, activation='sigmoid', name=\"output\")(hidden2)\n",
        "    model = Model(inputs=[input_node], outputs=output)\n",
        "    print(model.summary())\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvS0AuwUwlnx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model26_another_chance_for_2nd_dense_and_avg(input_len):\n",
        "    K.clear_session()\n",
        "    # tf.random.set_random_seed(5005)\n",
        "\n",
        "    input_node = Input(shape=(input_len, 4), name=\"input\")\n",
        "    conv0 = Conv1D(filters=90, kernel_size=1, padding='valid', activation=\"relu\", name=\"conv0\",kernel_regularizer=regularizers.l2(l2_lam))(input_node)\n",
        "    conv1 = Conv1D(filters=90, kernel_size=3, padding='valid', activation=\"relu\", name=\"conv1\",kernel_regularizer=regularizers.l2(l2_lam))(conv0)\n",
        "    pool1 = AveragePooling1D(pool_size=2, strides=1, name=\"pool1\")(conv1)\n",
        "    drop1 = Dropout(0.25, name=\"drop1\")(pool1)\n",
        "  \n",
        "    conv2 = Conv1D(filters=100, kernel_size=5, padding='valid', activation=\"relu\", name=\"conv2\", kernel_regularizer=regularizers.l2(l2_lam))(drop1)\n",
        "    pool2 = AveragePooling1D(pool_size=2, strides=1)(conv2)\n",
        "    drop2 = Dropout(0.25)(pool2)\n",
        "    flat = Flatten()(drop2)\n",
        "\n",
        "    hidden1 = Dense(500, activation='relu', name=\"hidden1\",kernel_regularizer=regularizers.l1(l1_lam))(flat)\n",
        "    drop3 = Dropout(0.25)(hidden1)\n",
        "    hidden2 = Dense(250, activation='relu', name=\"hidden2\",kernel_regularizer=regularizers.l1(l1_lam))(drop3)\n",
        "\n",
        "    output = Dense(1, activation='sigmoid', name=\"output\")(hidden2)\n",
        "    model = Model(inputs=[input_node], outputs=output)\n",
        "    print(model.summary())\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EvwOrwS-p3m4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Lv1OtwF_2FV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def deepripe_model(input_len):\n",
        "    K.clear_session()\n",
        "    # tf.random.set_random_seed(5005)\n",
        "\n",
        "    input_node = Input(shape=(input_len, 4), name=\"input\")\n",
        "    conv1 = Conv1D(filters=90, kernel_size=7, padding='valid', activation=\"relu\", name=\"conv1\")(input_node)\n",
        "    pool1 = MaxPooling1D(pool_size=4, strides=2, name=\"pool1\")(conv1)\n",
        "    drop1 = Dropout(0.25, name=\"drop1\")(pool1)\n",
        "\n",
        "    conv2 = Conv1D(filters=100, kernel_size=5, padding='valid', activation=\"relu\", name=\"conv2\")(drop1)\n",
        "    pool2  = MaxPooling1D(pool_size=10, strides=5)(conv2)\n",
        "    drop2  = Dropout(0.25)(pool2)\n",
        "    flat = Flatten()(drop2)\n",
        "\n",
        "    hidden1 = Dense(250, activation='relu', name=\"hidden1\")(flat)\n",
        "    output = Dense(1, activation='sigmoid', name=\"output\")(hidden1)\n",
        "    model = Model(inputs=[input_node], outputs=output)\n",
        "    print(model.summary())\n",
        "    return model\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8Qiovq3_1_5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_baseline(input_len):\n",
        "    K.clear_session()\n",
        "    # tf.random.set_random_seed(5005)\n",
        "\n",
        "    input_node = Input(shape=(input_len, 4), name=\"input\")\n",
        "    conv1 = Conv1D(filters=90, kernel_size=7, padding='valid', activation=\"relu\", name=\"conv1\")(input_node)\n",
        "    pool1 = MaxPooling1D(pool_size=4, strides=2, name=\"pool1\")(conv1)\n",
        "    drop1 = Dropout(0.25, name=\"drop1\")(pool1)\n",
        "  \n",
        "    conv2 = Conv1D(filters=100, kernel_size=5, padding='valid', activation=\"relu\", name=\"conv2\")(drop1)\n",
        "    pool2 = MaxPooling1D(pool_size=10, strides=5)(conv2)\n",
        "    drop2 = Dropout(0.25)(pool2)\n",
        "    flat = Flatten()(drop2)\n",
        "\n",
        "    hidden1 = Dense(500, activation='relu', name=\"hidden1\")(flat)\n",
        "    output = Dense(1, activation='sigmoid', name=\"output\")(hidden1)\n",
        "    model = Model(inputs=[input_node], outputs=output)\n",
        "    print(model.summary())\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OH7L0Du9ppbF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def deepripe_orig(input_len_l):\n",
        "  K.clear_session()\n",
        "  left_dim=4\n",
        "  right_dim=4\n",
        "  num_units=50\n",
        "  input_l=input_len_l\n",
        "\n",
        "  nb_f_l=[90,100]\n",
        "  f_len_l=[7,7]\n",
        "  p_len_l=[4,10]\n",
        "  s_l=[2,5]\n",
        "  nb_f_r=[90,100]\n",
        "  f_len_r=[7,7]\n",
        "  p_len_r=[10,10]\n",
        "  s_r=[5,5]\n",
        "\n",
        "  left_input = Input(shape=(input_l,left_dim),name=\"left_input\")\n",
        "\n",
        "  left_conv1 = Conv1D(filters=nb_f_l[0],kernel_size=f_len_l[0], padding='valid',activation=\"relu\",name=\"left_conv1\")(left_input)\n",
        "  left_pool1 = MaxPooling1D(pool_size=p_len_l[0], strides=s_l[0],name=\"left_pool1\")(left_conv1)\n",
        "  left_drop1 = Dropout(0.25,name=\"left_drop1\")(left_pool1)\n",
        "\n",
        "  conv_merged = Conv1D(filters=100,kernel_size= 5, padding='valid',activation=\"relu\",name=\"conv_merged\")(left_drop1)\n",
        "  merged_pool = MaxPooling1D(pool_size=10, strides=5)(conv_merged)\n",
        "  merged_drop = Dropout(0.25)(merged_pool)\n",
        "  merged_flat = Flatten()(merged_drop)\n",
        "\n",
        "  hidden1 = Dense(250, activation='relu',name=\"hidden1\")(merged_flat)\n",
        "  output = Dense(1, activation='sigmoid',name=\"output\")(hidden1)\n",
        "  model = Model(inputs=[left_input], outputs=output)\n",
        "  print(model.summary())\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TN9AfjIdppXl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcGySCcfdXQO",
        "colab_type": "text"
      },
      "source": [
        "Play\n"
      ]
    }
  ]
}