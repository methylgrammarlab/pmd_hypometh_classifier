{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "1wz-ud5Hav1O",
    "colab_type": "code",
    "outputId": "c53eadd7-f24b-48b9-9da1-f4f7c33f8dbc",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 151.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /gdrive\n",
      "/gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/gdrive')\n",
    "%cd /gdrive "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "vjO8Tu5MbI-0",
    "colab_type": "code",
    "outputId": "d1459bc5-06d1-413a-928b-e937880114cb",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/gdrive/My Drive/nn\n"
     ]
    }
   ],
   "source": [
    "cd /gdrive/My\\ Drive/nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "5BI8sNFMb0Lp",
    "colab_type": "code",
    "outputId": "a6a1716f-df4e-4e18-f951-b5ff2e1598b6",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow 1.x selected.\n"
     ]
    }
   ],
   "source": [
    "%tensorflow_version 1.x\n",
    "import argparse\n",
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(7)  # for reproducibility\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# tf.python.control_flow_ops = tf\n",
    "\n",
    "\n",
    "from tensorflow.python.keras.models import Model, load_model\n",
    "from tensorflow.python.keras.layers import Input\n",
    "from tensorflow.python.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.python.keras.layers.convolutional import Conv1D\n",
    "from tensorflow.python.keras.layers.pooling import MaxPooling1D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.python.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import tensorflow.python.keras.backend as K\n",
    "\n",
    "import matplotlib as mpl\n",
    "\n",
    "mpl.use('Agg')\n",
    "# from keras.utils.layer_utils import print_layer_shapes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l9HkC43yd88d",
    "colab_type": "text"
   },
   "source": [
    "load local scripts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "ed1rbfSZeAB9",
    "colab_type": "code",
    "outputId": "06199d63-d77a-45d1-f2a5-7ceebef7a681",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36.0
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "8WUFUDjsfk5H",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "sys.path.append(\".\")\n",
    "from utils import precision, recall, load_data_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "lHcO6wobeAjx",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "def create_seq_model(input_len):\n",
    "    \"\"\"\n",
    "    Create a sequence model\n",
    "    :param input_len: path to file (consist of train, valid and test data)\n",
    "    \"\"\"\n",
    "    K.clear_session()\n",
    "    #tf.random.set_seed(5005)\n",
    "\n",
    "    input_node = Input(shape=(input_len, 4), name=\"input\")\n",
    "    conv1 = Conv1D(filters=90, kernel_size=7, padding='valid', activation=\"relu\", name=\"conv1\")(input_node)\n",
    "    pool1 = MaxPooling1D(pool_size=4, strides=2, name=\"left_pool1\")(conv1)\n",
    "    drop1 = Dropout(0.25, name=\"left_drop1\")(pool1)\n",
    "  \n",
    "    if input_len > 10:\n",
    "        conv_merged = Conv1D(filters=100, kernel_size=5, padding='valid', activation=\"relu\", name=\"conv_merged\")(\n",
    "            drop1)\n",
    "        merged_pool = MaxPooling1D(pool_size=10, strides=5)(conv_merged)\n",
    "        merged_drop = Dropout(0.25)(merged_pool)\n",
    "        merged_flat = Flatten()(merged_drop)\n",
    "    else:\n",
    "        merged_flat = drop1 \n",
    "\n",
    "    hidden1 = Dense(250, activation='relu', name=\"hidden1\")(merged_flat)\n",
    "    output = Dense(1, activation='sigmoid', name=\"output\")(hidden1)\n",
    "    model = Model(inputs=[input_node], outputs=output)\n",
    "    print(model.summary())\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def train_diff_model(data_path, res_path, model_name, input_len,\n",
    "                     num_epoch, batchsize, model_path=\"./weights.hdf5\"):\n",
    "    \"\"\"\n",
    "    Training the model\n",
    "    :param data_path: path to file (consist of train, valid and test data)\n",
    "    :param res_path:\n",
    "    :param model_name:\n",
    "    :param input_len:\n",
    "    :param num_epoch:\n",
    "    :param batchsize:\n",
    "    :param model_path:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    print('creating model')\n",
    "    model = create_seq_model(input_len)\n",
    "    print('compiling model')\n",
    "    adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=1e-6)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy', precision, recall])\n",
    "    checkpointer = ModelCheckpoint(filepath=model_path, verbose=1, save_best_only=True)\n",
    "    earlystopper = EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "    # tb=TensorBoard(log_dir='./Output/logs', histogram_freq=0, write_graph=True, write_images=False)\n",
    "\n",
    "    print('loading data')\n",
    "    x_train_seq, y_train, x_valid_seq, y_valid, x_test_seq, y_test = load_data_merged(data_path, input_len)\n",
    "\n",
    "    print('fitting the model')\n",
    "    history = model.fit(x_train_seq, y_train, epochs=num_epoch, batch_size=batchsize,\n",
    "                        validation_data=(x_valid_seq, y_valid), verbose=2,\n",
    "                        callbacks=[checkpointer, earlystopper, ])  # tb])\n",
    "\n",
    "    print('saving the model')\n",
    "    model.save(os.path.join(res_path, model_name + \".h5\"))\n",
    "\n",
    "    print('testing the model')\n",
    "    score = model.evaluate(x_test_seq, y_test)\n",
    "\n",
    "    print(model.metrics_names)\n",
    "    for i in range(len(model.metrics_names)):\n",
    "        print(str(model.metrics_names[i]) + \": \" + str(score[i]))\n",
    "\n",
    "    print(\"{}: {:.2f}\".format(model.metrics_names[0], score[0]))\n",
    "    print(\"{}: {:.2f}\".format(model.metrics_names[1], score[1]))\n",
    "    print(\"{}: {:.2f}\".format(model.metrics_names[2], score[2]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "iuK-AGHSeAuL",
    "colab_type": "code",
    "outputId": "9d1d0788-286a-440e-cd9f-13e88ef0bca9",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000.0
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating model\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 150, 4)]          0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv1D)               (None, 144, 90)           2610      \n",
      "_________________________________________________________________\n",
      "left_pool1 (MaxPooling1D)    (None, 71, 90)            0         \n",
      "_________________________________________________________________\n",
      "left_drop1 (Dropout)         (None, 71, 90)            0         \n",
      "_________________________________________________________________\n",
      "conv_merged (Conv1D)         (None, 67, 100)           45100     \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 12, 100)           0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 12, 100)           0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1200)              0         \n",
      "_________________________________________________________________\n",
      "hidden1 (Dense)              (None, 250)               300250    \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 1)                 251       \n",
      "=================================================================\n",
      "Total params: 348,211\n",
      "Trainable params: 348,211\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "compiling model\n",
      "loading data\n",
      "fitting the model\n",
      "Train on 757132 samples, validate on 189284 samples\n",
      "Epoch 1/2\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.54580, saving model to saved_model\n",
      "757132/757132 - 110s - loss: 0.5594 - acc: 0.7145 - precision: 0.7106 - recall: 0.7226 - val_loss: 0.5458 - val_acc: 0.7293 - val_precision: 0.7138 - val_recall: 0.7706\n",
      "Epoch 2/2\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.54580 to 0.53828, saving model to saved_model\n",
      "757132/757132 - 109s - loss: 0.5467 - acc: 0.7258 - precision: 0.7212 - recall: 0.7373 - val_loss: 0.5383 - val_acc: 0.7306 - val_precision: 0.7418 - val_recall: 0.7105\n",
      "saving the model\n",
      "testing the model\n",
      "249568/249568 [==============================] - 17s 70us/sample - loss: 0.5125 - acc: 0.7540 - precision: 0.7460 - recall: 0.6947\n",
      "['loss', 'acc', 'precision', 'recall']\n",
      "loss: 0.5124864643973438\n",
      "acc: 0.7540109\n",
      "precision: 0.74601376\n",
      "recall: 0.694658\n",
      "loss: 0.51\n",
      "acc: 0.75\n",
      "precision: 0.75\n"
     ]
    }
   ],
   "source": [
    "train_diff_model(data_path=r\"dataset/classifier_data_ccpg1.pkl\", res_path=\".\", model_name=\"test\",\n",
    "                     input_len=150, num_epoch=2, batchsize=32,\n",
    "                     model_path=\"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "WUPZE76Fc1G1",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e6hquG5YZOe9",
    "colab_type": "text"
   },
   "source": [
    "**Interpet **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "OkZSB2s0wILH",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "!pip install concise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "OfH8jjFjboe5",
    "colab_type": "code",
    "outputId": "c542d540-75be-4b80-91c4-552f00960548",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 227.0
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-05 07:25:45,370 [INFO] Generating grammar tables from /usr/lib/python3.6/lib2to3/Grammar.txt\n",
      "2020-04-05 07:25:45,392 [INFO] Generating grammar tables from /usr/lib/python3.6/lib2to3/PatternGrammar.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-05 07:25:45,844 [WARNING] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "/gdrive/My Drive/nn/plotseqlogo.py:34: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  min_coords = np.vstack(data.min(0) for data in polygons_data).min(0)\n",
      "/gdrive/My Drive/nn/plotseqlogo.py:35: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  max_coords = np.vstack(data.max(0) for data in polygons_data).max(0)\n"
     ]
    }
   ],
   "source": [
    "import plotseqlogo\n",
    "import  IntegratedGradients\n",
    "from plotseqlogo import *\n",
    "from IntegratedGradients import *\n",
    "from utils import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "4Ye7WaxGcE2-",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 494.0
    },
    "outputId": "31c4c07e-692c-457e-d087-f4a4e524b8e2",
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-05 07:25:49,216 [WARNING] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-05 07:25:49,218 [WARNING] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-05 07:25:49,245 [WARNING] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-05 07:25:57,084 [WARNING] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = load_model(\"saved_model\",custom_objects={'precision': precision,'recall': recall })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "yeNWu7C2cPEO",
    "colab_type": "code",
    "outputId": "8bc3e7ec-a65e-44ee-dc0a-9eab5aadf40a",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 93.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated output channel (0-based index): All\n",
      "Building gradient functions\n",
      "\rProgress: 100.0%\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "gradients = integrated_gradients(model) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "taaV7zDHfWT-",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "x_train_seq, y_train, x_valid_seq, y_valid, x_test_seq, y_test = load_data_merged(r\"dataset/classifier_data_ccpg1.pkl\", 150, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "iT6BoFiHpb-O",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "ay1MN5GygG8i",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "samples = []\n",
    "numsteps = []\n",
    "step_sizes = []\n",
    "\n",
    "# _output = gradients.linearly_interpolate(x_test_seq[10])\n",
    "# samples.append(_output[0])\n",
    "# numsteps.append(_output[1])\n",
    "# step_sizes.append(_output[2])\n",
    "\n",
    "for i in range(100000):\n",
    "  _output = integrated_gradients.linearly_interpolate(x_test_seq[i], False, 50)\n",
    "  samples.append(_output[0])\n",
    "  numsteps.append(_output[1])\n",
    "  step_sizes.append(_output[2])\n",
    "\n",
    "\n",
    "\n",
    "_input = []\n",
    "for s in samples:\n",
    "    _input.append(s)\n",
    "_input.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "Z-vGfFobi2Lz",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "session = K.get_session()\n",
    "init = tf.global_variables_initializer()\n",
    "session.run(init)\n",
    "with session.as_default():\n",
    "    with session.graph.as_default():\n",
    "        gradients_l = gradients.get_gradients[0](_input)\n",
    "\n",
    "explanation = []\n",
    "for i in range(len(gradients_l)):\n",
    "    _temp = np.sum(gradients_l[i], axis=0)\n",
    "    explanation.append(np.multiply(_temp, step_sizes[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "aDfbxd1JmZt_",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "ex_seq = np.array(explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "gbqyQmiuo0S6",
    "colab_type": "code",
    "outputId": "4b015732-ed85-4935-d87b-e80e4d1a37f6",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 188.0
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.00199116],\n",
       "        [-0.        ],\n",
       "        [-0.        ],\n",
       "        [-0.        ]],\n",
       "\n",
       "       [[-0.        ],\n",
       "        [-0.        ],\n",
       "        [-0.        ],\n",
       "        [ 0.0017095 ]]])"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "1HQQ8UKFjODk",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "seqlogo_fig(np.transpose(ex_seq[:,60:90,:4],axes=(1,2,0)), figsize=(20, 4), ncol=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "GFcdwURPoVel",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "ex_seq"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "run_model",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
