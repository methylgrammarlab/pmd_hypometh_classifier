{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "1wz-ud5Hav1O",
    "colab_type": "code",
    "outputId": "37400656-3319-4c07-e038-28de0418adbc",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n",
      "/gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/gdrive')\n",
    "%cd /gdrive "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "vjO8Tu5MbI-0",
    "colab_type": "code",
    "outputId": "0257ecf3-57d8-492f-ad94-ed0ebb7f028d",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/gdrive/My Drive/nn\n"
     ]
    }
   ],
   "source": [
    "cd /gdrive/My\\ Drive/nn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "5BI8sNFMb0Lp",
    "colab_type": "code",
    "outputId": "0da05535-4ee3-4b56-e069-d2d16a583bac",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow 1.x selected.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%tensorflow_version 1.x\n",
    "import argparse\n",
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(7)  # for reproducibility\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.random.set_random_seed(5005)\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "\n",
    "# tf.python.control_flow_ops = tf\n",
    "\n",
    "\n",
    "from tensorflow.python.keras.models import Model, load_model\n",
    "from tensorflow.python.keras.layers import Input\n",
    "from tensorflow.python.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.python.keras.layers.convolutional import Conv1D\n",
    "from tensorflow.python.keras.layers.pooling import MaxPooling1D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.python.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import tensorflow.python.keras.backend as K\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import matplotlib as mpl\n",
    "\n",
    "mpl.use('Agg')\n",
    "import utils\n",
    "sys.path.append(\".\")\n",
    "from utils import precision, recall, load_data_merged\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "lHcO6wobeAjx",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "def train_diff_model(data_path, res_path, model_name, input_len,\n",
    "                     num_epoch, batchsize, model_path=\"./weights.hdf5\", \n",
    "                     number_of_folds=1, save=True):\n",
    "    \"\"\"\n",
    "    Training the model\n",
    "    :param data_path: path to file (consist of train, valid and test data)\n",
    "    :param res_path:\n",
    "    :param model_name:\n",
    "    :param input_len:\n",
    "    :param num_epoch:\n",
    "    :param batchsize:\n",
    "    :param model_path:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    print('creating model')\n",
    "    model = create_seq_model(input_len)\n",
    "    print('compiling model')\n",
    "    adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=1e-6)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "    checkpointer = ModelCheckpoint(filepath=model_path, verbose=1, save_best_only=True)\n",
    "    earlystopper = EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "\n",
    "    print('loading data')\n",
    "    x_train_list, y_train_list, x_valid_list, y_valid_list, x_test_seq, y_test = load_data_merged(data_path, input_len, kfold=number_of_folds)\n",
    "\n",
    "    print('fitting the model')\n",
    "    for i in range(len(x_train_list)):\n",
    "      print(\"Using fold %s/%s\" %(i+1, number_of_folds))\n",
    "      x_train_seq = x_train_list[i]\n",
    "      y_train = y_train_list[i]\n",
    "      x_valid_seq = x_valid_list[i]\n",
    "      y_valid = y_valid_list[i]\n",
    "\n",
    "      history = model.fit(x_train_seq, y_train, epochs=num_epoch, batch_size=batchsize,\n",
    "                          validation_data=(x_valid_seq, y_valid), verbose=2,\n",
    "                          callbacks=[checkpointer, earlystopper, ])  # tb])\n",
    "\n",
    "    if save:\n",
    "      print('saving the model')\n",
    "      model.save(os.path.join(res_path, model_name + \".h5\"))\n",
    "\n",
    "    print('testing the model')\n",
    "    score = model.evaluate(x_test_seq, y_test)\n",
    "\n",
    "    for i in range(len(model.metrics_names)):\n",
    "        print(str(model.metrics_names[i]) + \": \" + str(score[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "0xwMTa_vbH8-",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "train_diff_model(data_path=r\"dataset/classifier_data_ccpg1.pkl\", \n",
    "                 res_path=\"./models\", model_name=\"150cpg\", model_path=\"./models/temp/1\",\n",
    "                 input_len=150, num_epoch=20, batchsize=128, number_of_folds=10,save=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "06GOBU5s_3Y7",
    "colab_type": "text"
   },
   "source": [
    "**Models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "7Lv1OtwF_2FV",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "def deepripe_model(input_len):\n",
    "    K.clear_session()\n",
    "    tf.random.set_random_seed(5005)\n",
    "\n",
    "    input_node = Input(shape=(input_len, 4), name=\"input\")\n",
    "    conv1 = Conv1D(filters=90, kernel_size=7, padding='valid', activation=\"relu\", name=\"conv1\")(input_node)\n",
    "    pool1 = MaxPooling1D(pool_size=4, strides=2, name=\"pool1\")(conv1)\n",
    "    drop1 = Dropout(0.25, name=\"drop1\")(pool1)\n",
    "\n",
    "    conv2 = Conv1D(filters=100, kernel_size=5, padding='valid', activation=\"relu\", name=\"conv2\")(drop1)\n",
    "    pool2  = MaxPooling1D(pool_size=10, strides=5)(conv2)\n",
    "    drop2  = Dropout(0.25)(pool2)\n",
    "    flat = Flatten()(drop2)\n",
    "\n",
    "    hidden1 = Dense(250, activation='relu', name=\"hidden1\")(flat)\n",
    "    output = Dense(1, activation='sigmoid', name=\"output\")(hidden1)\n",
    "    model = Model(inputs=[input_node], outputs=output)\n",
    "    print(model.summary())\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "V8Qiovq3_1_5",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "def model_baseline(input_len):\n",
    "    K.clear_session()\n",
    "    tf.random.set_random_seed(5005)\n",
    "\n",
    "    input_node = Input(shape=(input_len, 4), name=\"input\")\n",
    "    conv1 = Conv1D(filters=90, kernel_size=7, padding='valid', activation=\"relu\", name=\"conv1\")(input_node)\n",
    "    pool1 = MaxPooling1D(pool_size=4, strides=2, name=\"pool1\")(conv1)\n",
    "    drop1 = Dropout(0.25, name=\"drop1\")(pool1)\n",
    "  \n",
    "    conv2 = Conv1D(filters=100, kernel_size=5, padding='valid', activation=\"relu\", name=\"conv2\")(drop1)\n",
    "    pool2 = MaxPooling1D(pool_size=10, strides=5)(conv2)\n",
    "    drop2 = Dropout(0.25)(pool2)\n",
    "    flat = Flatten()(drop2)\n",
    "\n",
    "    hidden1 = Dense(500, activation='relu', name=\"hidden1\")(flat)\n",
    "    output = Dense(1, activation='sigmoid', name=\"output\")(hidden1)\n",
    "    model = Model(inputs=[input_node], outputs=output)\n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "Bt62ih1b_17V",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "5AHXK8pY_13v",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "UE6EMiPf_1xz",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "h4jDpv36_1sj",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "run_model.ipynb",
   "provenance": [],
   "collapsed_sections": [],
   "machine_shape": "hm"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
